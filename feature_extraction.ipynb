{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from the processed and augmented audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Data processing and scientific computing\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared csv\n",
    "augmented_data = pd.read_csv(\"augmented_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_audio(audio, sr, min_duration=0.1, silence_threshold=-60):\n",
    "    \"\"\"Check if the audio segment is valid (not too short and not silent).\"\"\"\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    if duration < min_duration:\n",
    "        return False\n",
    "    \n",
    "    # Check if the audio is mostly silent\n",
    "    db = librosa.amplitude_to_db(np.abs(audio), ref=np.max)\n",
    "    if np.mean(db) < silence_threshold:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def extract_features(audio, sr):\n",
    "    # Mel-spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    \n",
    "    return {\n",
    "        'mel_spectrogram_db': mel_spec_db,\n",
    "        'mfccs': mfccs,\n",
    "        'spectral_centroids': spectral_centroids,\n",
    "        'chroma': chroma,\n",
    "        'zero_crossing_rate': zero_crossing_rate,\n",
    "        'spectral_rolloff': spectral_rolloff\n",
    "    }\n",
    "\n",
    "def summarize_feature(feature):\n",
    "    if feature.ndim == 1:\n",
    "        return np.array([np.mean(feature), np.std(feature), np.max(feature)])\n",
    "    elif feature.ndim == 2:\n",
    "        return np.hstack([\n",
    "            np.mean(feature, axis=1),\n",
    "            np.std(feature, axis=1),\n",
    "            np.max(feature, axis=1)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feature dimension: {feature.ndim}\")\n",
    "    \n",
    "def save_mel_spectrogram(mel_spec, output_dir, base_filename, sr):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spec, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{base_filename}_mel_spectrogram.png\"))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(file_path, output_dir):\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Check if audio segment is valid\n",
    "        if not is_valid_audio(audio, sr):\n",
    "            print(f\"Warning: Audio file {file_path} is too short or silent. Skipping.\")\n",
    "            return None, None\n",
    "        \n",
    "        # Extract features\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            features = extract_features(audio, sr)\n",
    "        \n",
    "        # Summarize features\n",
    "        feature_summary = {}\n",
    "        for key, value in features.items():\n",
    "            if key != 'mel_spectrogram_db':\n",
    "                feature_summary[f\"{key}_summary\"] = summarize_feature(value)\n",
    "        \n",
    "        # Create feature vector\n",
    "        feature_vector = np.hstack([\n",
    "            feature_summary.get('mfccs_summary', np.array([])),\n",
    "            feature_summary.get('spectral_centroids_summary', np.array([])),\n",
    "            feature_summary.get('chroma_summary', np.array([])),\n",
    "            feature_summary.get('zero_crossing_rate_summary', np.array([])),\n",
    "            feature_summary.get('spectral_rolloff_summary', np.array([]))\n",
    "        ])\n",
    "        \n",
    "        # Save mel-spectrogram as image\n",
    "        base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        save_mel_spectrogram(features['mel_spectrogram_db'], output_dir, base_filename, sr)\n",
    "        \n",
    "        return feature_vector, features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def process_audio_files_batch(df, base_dir, batch_size=1000):\n",
    "    feature_data = []\n",
    "    skipped_files = []\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        for _, row in tqdm(batch.iterrows(), total=len(batch)):\n",
    "            possible_paths = [\n",
    "                os.path.join(base_dir, 'Augmented Recordings', row['processed_file']),\n",
    "                os.path.join(base_dir, 'Processed Recordings', row['processed_file'])\n",
    "            ]\n",
    "            \n",
    "            file_path = next((path for path in possible_paths if os.path.exists(path)), None)\n",
    "            \n",
    "            if file_path is None:\n",
    "                print(f\"File not found: {row['processed_file']}\")\n",
    "                skipped_files.append(row['processed_file'])\n",
    "                continue\n",
    "            \n",
    "            feature_vector = process_audio_file(file_path)\n",
    "            \n",
    "            if feature_vector is not None:\n",
    "                feature_data.append({\n",
    "                    'processed_file': row['processed_file'],\n",
    "                    'feature_vector': feature_vector,\n",
    "                })\n",
    "            else:\n",
    "                skipped_files.append(row['processed_file'])\n",
    "        \n",
    "        # Garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"Total files skipped: {len(skipped_files)}\")\n",
    "    return feature_data, skipped_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random file\n",
    "random_file = random.choice(augmented_data['processed_file'])\n",
    "possible_paths = [\n",
    "    os.path.join('Augmented Recordings', random_file),\n",
    "    os.path.join('Processed Recordings', random_file)\n",
    "]\n",
    "file_path = next((path for path in possible_paths if os.path.exists(path)), None)\n",
    "\n",
    "if file_path is None:\n",
    "    print(f\"Error: File not found - {random_file}\")\n",
    "else:\n",
    "    print(f\"Testing feature extraction on file: {file_path}\")\n",
    "\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(audio, sr)\n",
    "\n",
    "    # Print a summary of each feature\n",
    "    for feature_name, feature_data in features.items():\n",
    "        if feature_name == 'mel_spectrogram_db':\n",
    "            print(f\"{feature_name} shape: {feature_data.shape}\")\n",
    "        else:\n",
    "            print(f\"{feature_name} shape: {feature_data.shape}, mean: {np.mean(feature_data):.4f}, std: {np.std(feature_data):.4f}\")\n",
    "\n",
    "    # Summarize features\n",
    "    feature_summary = {}\n",
    "    for key, value in features.items():\n",
    "        if key != 'mel_spectrogram_db':\n",
    "            feature_summary[f\"{key}_summary\"] = summarize_feature(value)\n",
    "\n",
    "    # Print summary of summarized features\n",
    "    print(\"\\nSummarized Features:\")\n",
    "    for key, value in feature_summary.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"{key} type: numpy.ndarray, shape: {value.shape}, mean: {np.mean(value):.4f}, std: {np.std(value):.4f}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"{key} type: list, length: {len(value)}, first few elements: {value[:5]}\")\n",
    "        else:\n",
    "            print(f\"{key} type: {type(value)}, value: {value}\")\n",
    "\n",
    "    # Create feature vector\n",
    "    feature_vector = []\n",
    "    for key in ['mfccs_summary', 'spectral_centroids_summary', 'chroma_summary', 'zero_crossing_rate_summary', 'spectral_rolloff_summary']:\n",
    "        value = feature_summary.get(key, np.array([]))\n",
    "        if isinstance(value, list):\n",
    "            feature_vector.extend(value)\n",
    "        else:\n",
    "            feature_vector.append(value)\n",
    "    \n",
    "    feature_vector = np.hstack(feature_vector)\n",
    "\n",
    "    print(f\"\\nFinal feature vector shape: {feature_vector.shape}\")\n",
    "\n",
    "    # Save mel-spectrogram as image\n",
    "    output_dir = 'Test'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    save_mel_spectrogram(features['mel_spectrogram_db'], output_dir, base_filename, sr)\n",
    "\n",
    "    print(f\"Mel-spectrogram saved as: {base_filename}_mel_spectrogram.png in {output_dir}\")\n",
    "\n",
    "print(\"Feature extraction test complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "output_dir = 'mel-spectrograms'\n",
    "\n",
    "feature_data, skipped_files = process_audio_files_batch(augmented_data, base_dir)\n",
    "\n",
    "# Convert feature_data to DataFrame\n",
    "feature_df = pd.DataFrame(feature_data)\n",
    "\n",
    "# Merge the new feature DataFrame with the existing final_data DataFrame\n",
    "final_data = pd.merge(augmented_data, feature_df, on='processed_file', how='left')\n",
    "\n",
    "# Drop rows corresponding to skipped files\n",
    "final_data = final_data[~final_data['processed_file'].isin(skipped_files)]\n",
    "\n",
    "print(final_data.info())\n",
    "\n",
    "print(f\"\\nTotal files in augmented_data: {len(augmented_data)}\")\n",
    "print(f\"Files successfully processed: {len(feature_df)}\")\n",
    "print(f\"Files skipped (too short or silent): {len(skipped_files)}\")\n",
    "print(f\"Files in final_data after dropping skipped files: {len(final_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the dataframe\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "final_data.to_csv('final_data.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Summary data saved to 'final_data.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
