{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "# Data processing and scientific computing\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing\n",
    "    - Remove low-quality or noisy recordings based on metadata if available, or by manually inspecting a few samples.\n",
    "\t    - It's a good idea to manually inspect some of the longer clips, especially outliers.\n",
    "\t    - - Listen for: a) Consistency of the bird call throughout the clip b) Presence of long periods of silence c) Sudden changes in background noise or environment\n",
    "\t\t- If you find issues, you might consider trimming these clips to the most relevant sections before segmenting.\n",
    "\t\t- - Definitely inspect a sample of low-rated files.\n",
    "\t\t- Listen for: a) Clarity of the bird call b) Signal-to-noise ratio (how clear the bird call is compared to background noise) c) Presence of distortions or artifacts\n",
    "\t\t- Consider setting a threshold for the quality rating, below which you might exclude files from your dataset.\n",
    "\t\t- Determining if a file is too \"noisy\":\n",
    "\n",
    "\t\t- This can be subjective, but here are some approaches: a) Signal-to-Noise Ratio (SNR): Calculate the SNR for each file. Files below a certain threshold could be considered too noisy. b) Spectral analysis: Look at the spectrogram. A very noisy file will have a lot of energy spread across all frequencies. c) Perceptual evaluation: Listen to a sample and rate them yourself. This can help you calibrate your automatic methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genus', 'species', 'latitude', 'longitude', 'type', 'quality',\n",
       "       'file_name', 'simplified_type', 'season', 'time_of_day',\n",
       "       'length_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The metadata contains a column with a 'quality' rating. I'll manually examine those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "A           273\n",
       "B           261\n",
       "C           116\n",
       "D            32\n",
       "E             4\n",
       "no score      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>type</th>\n",
       "      <th>quality</th>\n",
       "      <th>file_name</th>\n",
       "      <th>simplified_type</th>\n",
       "      <th>season</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>length_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Vireo</td>\n",
       "      <td>bellii</td>\n",
       "      <td>39.20950</td>\n",
       "      <td>-84.78210</td>\n",
       "      <td>song</td>\n",
       "      <td>E</td>\n",
       "      <td>Vireo_bellii_Whitewater_Township_near__Harriso...</td>\n",
       "      <td>Song</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Evening</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Baeolophus</td>\n",
       "      <td>bicolor</td>\n",
       "      <td>40.94200</td>\n",
       "      <td>-81.52360</td>\n",
       "      <td>call</td>\n",
       "      <td>no score</td>\n",
       "      <td>Baeolophus_bicolor_Ohio_near__Akron_Summit_Cou...</td>\n",
       "      <td>Call</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Tachycineta</td>\n",
       "      <td>bicolor</td>\n",
       "      <td>41.96820</td>\n",
       "      <td>-82.53050</td>\n",
       "      <td>call</td>\n",
       "      <td>no score</td>\n",
       "      <td>Tachycineta_bicolor_Pelee_near__Leamington_Ess...</td>\n",
       "      <td>Call</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Morning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Spizella</td>\n",
       "      <td>passerina</td>\n",
       "      <td>41.93338</td>\n",
       "      <td>-83.54994</td>\n",
       "      <td>song</td>\n",
       "      <td>E</td>\n",
       "      <td>Spizella_passerina_Michigan_Monroe_County_1717...</td>\n",
       "      <td>Song</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Spizella</td>\n",
       "      <td>pusilla</td>\n",
       "      <td>39.88880</td>\n",
       "      <td>-82.79780</td>\n",
       "      <td>song</td>\n",
       "      <td>no score</td>\n",
       "      <td>Spizella_pusilla_Madison_Township_near__Canal_...</td>\n",
       "      <td>Song</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Melospiza</td>\n",
       "      <td>melodia</td>\n",
       "      <td>41.93338</td>\n",
       "      <td>-83.54994</td>\n",
       "      <td>song</td>\n",
       "      <td>E</td>\n",
       "      <td>Melospiza_melodia_Michigan_Monroe_County_17143...</td>\n",
       "      <td>Song</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Geothlypis</td>\n",
       "      <td>trichas</td>\n",
       "      <td>41.18950</td>\n",
       "      <td>-81.57810</td>\n",
       "      <td>song</td>\n",
       "      <td>E</td>\n",
       "      <td>Geothlypis_trichas_Ohio_near__Peninsula_Summit...</td>\n",
       "      <td>Song</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Morning</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Sonus</td>\n",
       "      <td>naturalis</td>\n",
       "      <td>41.43300</td>\n",
       "      <td>-81.41800</td>\n",
       "      <td>song</td>\n",
       "      <td>no score</td>\n",
       "      <td>Sonus_naturalis_Chagrin_Falls_Township_near__M...</td>\n",
       "      <td>Song</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           genus    species  latitude  longitude  type   quality  \\\n",
       "182        Vireo     bellii  39.20950  -84.78210  song         E   \n",
       "197   Baeolophus    bicolor  40.94200  -81.52360  call  no score   \n",
       "227  Tachycineta    bicolor  41.96820  -82.53050  call  no score   \n",
       "364     Spizella  passerina  41.93338  -83.54994  song         E   \n",
       "365     Spizella    pusilla  39.88880  -82.79780  song  no score   \n",
       "395    Melospiza    melodia  41.93338  -83.54994  song         E   \n",
       "562   Geothlypis    trichas  41.18950  -81.57810  song         E   \n",
       "685        Sonus  naturalis  41.43300  -81.41800  song  no score   \n",
       "\n",
       "                                             file_name simplified_type  \\\n",
       "182  Vireo_bellii_Whitewater_Township_near__Harriso...            Song   \n",
       "197  Baeolophus_bicolor_Ohio_near__Akron_Summit_Cou...            Call   \n",
       "227  Tachycineta_bicolor_Pelee_near__Leamington_Ess...            Call   \n",
       "364  Spizella_passerina_Michigan_Monroe_County_1717...            Song   \n",
       "365  Spizella_pusilla_Madison_Township_near__Canal_...            Song   \n",
       "395  Melospiza_melodia_Michigan_Monroe_County_17143...            Song   \n",
       "562  Geothlypis_trichas_Ohio_near__Peninsula_Summit...            Song   \n",
       "685  Sonus_naturalis_Chagrin_Falls_Township_near__M...            Song   \n",
       "\n",
       "     season time_of_day  length_seconds  \n",
       "182  Summer     Evening               3  \n",
       "197  Summer     Morning              15  \n",
       "227  Spring     Morning               2  \n",
       "364  Summer     Unknown              28  \n",
       "365  Spring   Afternoon              20  \n",
       "395  Summer     Unknown              34  \n",
       "562  Summer     Morning              30  \n",
       "685  Spring   Afternoon              28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "low_quality_files = data[(data['quality'] == 'E') | (data['quality'] == 'no score')]\n",
    "display(low_quality_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert mp3 to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(mp3_path, wav_path):\n",
    "    \"\"\"\n",
    "    Convert an MP3 file to WAV format using librosa and soundfile.\n",
    "    \n",
    "    Args:\n",
    "    mp3_path (str): Path to the input MP3 file\n",
    "    wav_path (str): Path to save the output WAV file\n",
    "    \n",
    "    Returns:\n",
    "    str: Path to the created WAV file\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the input MP3 file is not found\n",
    "    \"\"\"\n",
    "    if not os.path.exists(mp3_path):\n",
    "        raise FileNotFoundError(f\"MP3 file not found: {mp3_path}\")\n",
    "    \n",
    "    # Load the mp3 file\n",
    "    audio, sr = librosa.load(mp3_path, sr=None, mono=False)\n",
    "    \n",
    "    # Save as wav\n",
    "    sf.write(wav_path, audio.T, sr)\n",
    "    \n",
    "    return wav_path\n",
    "\n",
    "def batch_convert_to_wav(data, input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Convert all MP3 files in the dataset to WAV format.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame containing file information\n",
    "    input_dir (str): Directory containing the input MP3 files\n",
    "    output_dir (str): Directory to save the output WAV files\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (pd.DataFrame, list) Updated DataFrame with new file paths and list of files not found\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    new_data = data.copy()\n",
    "    files_not_found = []\n",
    "    \n",
    "    for index, row in new_data.iterrows():\n",
    "        mp3_path = os.path.join(input_dir, row['file_name'])\n",
    "        wav_filename = os.path.splitext(row['file_name'])[0] + '.wav'\n",
    "        wav_path = os.path.join(output_dir, wav_filename)\n",
    "        \n",
    "        try:\n",
    "            convert_mp3_to_wav(mp3_path, wav_path)\n",
    "            new_data.at[index, 'file_name'] = wav_filename\n",
    "        except FileNotFoundError:\n",
    "            files_not_found.append(row['file_name'])\n",
    "            new_data = new_data.drop(index)\n",
    "    \n",
    "    return new_data.reset_index(drop=True), files_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting MP3 files to WAV...\n",
      "Conversion complete. 689 files converted.\n",
      "WAV files saved in: Converted Recordings\n",
      "Number of files not found: 1\n",
      "List of files not found:\n",
      "['Colaptes_auratus_Miami_Township_near__North_Bend_Hamilton_County_Ohio_713588.mp3']\n"
     ]
    }
   ],
   "source": [
    "original_dir = 'Original Recordings'\n",
    "converted_dir = 'Converted Recordings'\n",
    "\n",
    "# Convert the MP3 files to WAV\n",
    "print(\"Converting MP3 files to WAV...\")\n",
    "converted_data, missing_files = batch_convert_to_wav(data, original_dir, converted_dir)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Conversion complete. {len(converted_data)} files converted.\")\n",
    "print(f\"WAV files saved in: {converted_dir}\")\n",
    "print(f\"Number of files not found: {len(missing_files)}\")\n",
    "\n",
    "# If you want to examine the list of missing files\n",
    "print(\"List of files not found:\")\n",
    "print(missing_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Audio Cleaning Functions\n",
    "\n",
    "These functions collectively clean an audio file by:\n",
    "1. Calculating its signal-to-noise ratio (SNR) and filtering out audio that is too noisy.\n",
    "2. Detecting and trimming long silences from the audio.\n",
    "3. Checking for spectral spread, which is an indicator of unwanted noise or anomalies.\n",
    "\n",
    "Main function:\n",
    "- `clean_audio`: Uses `is_too_noisy`, `has_long_silence`, and `check_spectral_spread` to decide if an audio file is suitable for further processing.\n",
    "\"\"\"\n",
    "\n",
    "- **Feature Extraction with Librosa**:\n",
    "    - Extract features like **Mel-spectrograms** and **MFCCs** from each audio file. These features are effective for audio classification tasks.\n",
    "    - Store these features as images (for CNN input) or numerical arrays (for models like Random Forest or RNNs).\n",
    "\n",
    "    - **Audio Standardization**:\n",
    "    - Convert all files to a consistent format (e.g., 16-bit WAV, mono-channel, and a sampling rate like 16 kHz).\n",
    "- **Clip Standardization**:\n",
    "    - Trim or pad each audio clip to a standard duration (e.g., 5 seconds), so all inputs have the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with resampling so every file has the same sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling process complete.\n",
      "Total files checked: 688\n",
      "Files resampled: 311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def resample_audio(file_path, target_sr=44100):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if sr != target_sr:\n",
    "            audio = librosa.resample(y=audio, orig_sr=sr, target_sr=target_sr)\n",
    "            \n",
    "            # Overwrite the original file\n",
    "            sf.write(file_path, audio, target_sr)\n",
    "            \n",
    "            return True  # Indicate that resampling was performed\n",
    "        else:\n",
    "            return False  # Indicate that no resampling was needed\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def resample_all_files(directory='Converted Recordings', target_sr=44100):\n",
    "    total_files = 0\n",
    "    resampled_files = 0\n",
    "    error_files = 0\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):  # Assuming we're only processing .wav files\n",
    "            total_files += 1\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            result = resample_audio(file_path, target_sr)\n",
    "            if result is True:\n",
    "                resampled_files += 1\n",
    "            elif result is None:\n",
    "                error_files += 1\n",
    "    \n",
    "    print(f\"Resampling process complete.\")\n",
    "    print(f\"Total files checked: {total_files}\")\n",
    "    print(f\"Files resampled: {resampled_files}\")\n",
    "    if error_files > 0:\n",
    "        print(f\"Files with errors: {error_files}\")\n",
    "\n",
    "# Usage\n",
    "logging.basicConfig(level=logging.ERROR)  # Only log errors\n",
    "resample_all_files('Converted Recordings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snr(audio):\n",
    "    \"\"\"Calculate the signal-to-noise ratio of an audio clip.\"\"\"\n",
    "    signal = np.mean(audio**2)\n",
    "    noise = np.mean((audio - np.mean(audio))**2)\n",
    "    snr = 10 * np.log10(signal / noise)\n",
    "    return snr\n",
    "\n",
    "def is_too_noisy(audio, sr, threshold=-20):\n",
    "    \"\"\"Check if audio is too noisy based on its SNR.\"\"\"\n",
    "    snr = calculate_snr(audio)\n",
    "    return snr < threshold\n",
    "\n",
    "def has_long_silence(audio, sr, silence_threshold=-60, min_silence_duration=1.0):\n",
    "    \"\"\"Detects long silences within the audio clip.\"\"\"\n",
    "    intervals = librosa.effects.split(audio, top_db=-silence_threshold)\n",
    "    if len(intervals) > 1:\n",
    "        silence_durations = np.diff(intervals.ravel())[1::2] / sr\n",
    "        return np.any(silence_durations >= min_silence_duration)\n",
    "    return False\n",
    "\n",
    "def check_spectral_spread(audio, sr, threshold=0.8):\n",
    "    \"\"\"Check if the spectral spread exceeds the specified threshold.\"\"\"\n",
    "    spec = np.abs(librosa.stft(audio))\n",
    "    spectral_spread = np.sum(spec > np.mean(spec)) / spec.size\n",
    "    return spectral_spread > threshold\n",
    "\n",
    "def clean_audio(audio, sr, file_path, shared_discarded_files):\n",
    "    \"\"\"Cleans an audio file by removing noise, silence, and checking for spectral spread.\"\"\"\n",
    "    # Get file name for logging\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Check noise level\n",
    "    if is_too_noisy(audio, sr):\n",
    "        shared_discarded_files.append({'file_path': file_path, 'reason': 'too_noisy', 'snr': calculate_snr(audio)})\n",
    "        return None\n",
    "    \n",
    "    # Check for long silences\n",
    "    if has_long_silence(audio, sr):\n",
    "        audio = librosa.effects.trim(audio, top_db=20)[0]\n",
    "    \n",
    "    # Check spectral spread\n",
    "    if check_spectral_spread(audio, sr):\n",
    "        shared_discarded_files.append({'file_path': file_path, 'reason': 'bad_spectral_spread'})\n",
    "        return None\n",
    "    \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the functions on a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genus', 'species', 'latitude', 'longitude', 'type', 'quality',\n",
       "       'file_name', 'simplified_type', 'season', 'time_of_day',\n",
       "       'length_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_snr completed. SNR: 0.009944349294528365\n",
      "is_too_noisy completed. Result: False\n",
      "has_long_silence completed. Result: False\n",
      "check_spectral_spread completed. Result: False\n",
      "clean_audio completed. Cleaned audio returned: Yes\n",
      "\n",
      "Tested file: Converted Recordings\\Sitta_carolinensis_Lawrence_Woods_SNP_417999.wav\n"
     ]
    }
   ],
   "source": [
    "# Define sample rate\n",
    "sr = 44100\n",
    "\n",
    "# Choose a random file\n",
    "random_file = random.choice(converted_data['file_name'].tolist())\n",
    "file_path = os.path.join('Converted Recordings', random_file)\n",
    "\n",
    "# Load the audio file\n",
    "audio, _ = librosa.load(file_path, sr=sr)\n",
    "\n",
    "# Test calculate_snr function\n",
    "snr = calculate_snr(audio)\n",
    "print(f\"calculate_snr completed. SNR: {snr}\")\n",
    "\n",
    "# Test is_too_noisy function\n",
    "too_noisy = is_too_noisy(audio, sr)\n",
    "print(f\"is_too_noisy completed. Result: {too_noisy}\")\n",
    "\n",
    "# Test has_long_silence function\n",
    "long_silence = has_long_silence(audio, sr)\n",
    "print(f\"has_long_silence completed. Result: {long_silence}\")\n",
    "\n",
    "# Test check_spectral_spread function\n",
    "spectral_spread = check_spectral_spread(audio, sr)\n",
    "print(f\"check_spectral_spread completed. Result: {spectral_spread}\")\n",
    "\n",
    "# Test clean_audio function\n",
    "shared_discarded_files = []\n",
    "cleaned_audio = clean_audio(audio, sr, file_path, shared_discarded_files)\n",
    "print(f\"clean_audio completed. Cleaned audio returned: {'Yes' if cleaned_audio is not None else 'No'}\")\n",
    "if shared_discarded_files:\n",
    "    print(f\"File discarded. Reason: {shared_discarded_files[0]['reason']}\")\n",
    "\n",
    "print(f\"\\nTested file: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test duplication functions two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_fingerprint(audio, sr):\n",
    "    n_fft = min(2048, len(audio))\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_fft=n_fft)\n",
    "    return np.mean(mfccs, axis=1)\n",
    "\n",
    "def are_near_duplicates(audio1, sr1, audio2, sr2, threshold=0.99):\n",
    "    if len(audio1) == 0 or len(audio2) == 0:\n",
    "        raise ValueError(\"One or both audio files are empty\")\n",
    "    \n",
    "    if sr1 != sr2:\n",
    "        print(f\"Warning: Sample rates differ ({sr1} vs {sr2}). Resampling may be necessary.\")\n",
    "    \n",
    "    fp1 = get_audio_fingerprint(audio1, sr1)\n",
    "    fp2 = get_audio_fingerprint(audio2, sr2)\n",
    "    \n",
    "    if len(fp1) != len(fp2):\n",
    "        raise ValueError(\"Fingerprints have different lengths\")\n",
    "    \n",
    "    similarity = 1 - cosine(fp1, fp2)\n",
    "    return similarity > threshold\n",
    "\n",
    "def check_audio_duplicates(file_path, shared_duplicates, shared_discarded_files):\n",
    "    try:\n",
    "        # Load the audio\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Check for duplicates\n",
    "        for existing_audio, existing_sr, existing_path in shared_duplicates:\n",
    "            if are_near_duplicates(audio, sr, existing_audio, existing_sr):\n",
    "                shared_discarded_files.append((file_path, 'duplicate'))\n",
    "                return True  # It's a duplicate\n",
    "\n",
    "        # If not a duplicate, store the audio and path\n",
    "        shared_duplicates.append((audio, sr, file_path))\n",
    "        return False  # It's not a duplicate\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking duplicates for {file_path}: {str(e)}\")\n",
    "        shared_discarded_files.append((file_path, f'error: {str(e)}'))\n",
    "        return None  # Error occurred\n",
    "\n",
    "def check_and_remove_duplicates(directory='Converted Recordings'):\n",
    "    shared_duplicates = []\n",
    "    shared_discarded_files = []\n",
    "    duplicate_files = []\n",
    "    total_files = 0\n",
    "\n",
    "    # Check each file in the directory for duplicates\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):  # Assuming we're only processing .wav files\n",
    "            total_files += 1\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            is_duplicate = check_audio_duplicates(file_path, shared_duplicates, shared_discarded_files)\n",
    "            if is_duplicate:\n",
    "                duplicate_files.append(file_path)\n",
    "\n",
    "    # Log the results\n",
    "    print(f\"Total files checked: {total_files}\")\n",
    "    print(f\"Duplicate files found: {len(duplicate_files)}\")\n",
    "\n",
    "    return duplicate_files, shared_discarded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing get_audio_fingerprint function:\n",
      "get_audio_fingerprint completed for file 1.\n",
      "Fingerprint shape: (13,)\n",
      "Fingerprint: [-529.6549     121.64817     14.872647    17.422089     7.4255624\n",
      "   13.47984      6.8169374   15.240807    13.116058    13.525121\n",
      "    5.887089     8.244506     6.326857 ]\n",
      "get_audio_fingerprint completed for file 2.\n",
      "Fingerprint shape: (13,)\n",
      "Fingerprint: [-426.08206      71.43607     -25.690928     37.489365     -8.012738\n",
      "    1.9857937     0.83789736   10.96637     -18.931467     12.174231\n",
      "    5.6113076    -7.4087596     3.7084825 ]\n",
      "\n",
      "Testing are_near_duplicates function:\n",
      "Threshold: 0.95\n",
      "Similarity score: 0.9894492604592912\n",
      "Result: The two files are near duplicates.\n",
      "Threshold: 0.99\n",
      "Similarity score: 0.9894492604592912\n",
      "Result: The two files are not near duplicates.\n",
      "Threshold: 0.999\n",
      "Similarity score: 0.9894492604592912\n",
      "Result: The two files are not near duplicates.\n",
      "\n",
      "Tested files:\n",
      "File 1: Converted Recordings\\Toxostoma_rufum_Point_Pelee_National_Park_near__Wheatley_Essex_County_Ontario_803578.wav\n",
      "File 2: Converted Recordings\\Colinus_virginianus_New_Market_Township_near__Hoagland_Highland_County_Ohio_805814.wav\n"
     ]
    }
   ],
   "source": [
    "### Check duplicate checking functions on two files\n",
    "\n",
    "# Define sample rate\n",
    "sr = 44100\n",
    "\n",
    "# Choose two random files\n",
    "random_files = random.sample(converted_data['file_name'].tolist(), 2)\n",
    "file_paths = [os.path.join('Converted Recordings', file) for file in random_files]\n",
    "\n",
    "# Load the audio files\n",
    "audio1, _ = librosa.load(file_paths[0], sr=sr)\n",
    "audio2, _ = librosa.load(file_paths[1], sr=sr)\n",
    "\n",
    "# Test get_audio_fingerprint function\n",
    "print(\"Testing get_audio_fingerprint function:\")\n",
    "fingerprint1 = get_audio_fingerprint(audio1, sr)\n",
    "print(f\"get_audio_fingerprint completed for file 1.\")\n",
    "print(f\"Fingerprint shape: {fingerprint1.shape}\")\n",
    "print(f\"Fingerprint: {fingerprint1}\")\n",
    "\n",
    "fingerprint2 = get_audio_fingerprint(audio2, sr)\n",
    "print(f\"get_audio_fingerprint completed for file 2.\")\n",
    "print(f\"Fingerprint shape: {fingerprint2.shape}\")\n",
    "print(f\"Fingerprint: {fingerprint2}\")\n",
    "\n",
    "# Test are_near_duplicates function with different thresholds\n",
    "print(\"\\nTesting are_near_duplicates function:\")\n",
    "thresholds = [0.95, 0.99, 0.999]\n",
    "for threshold in thresholds:\n",
    "    try:\n",
    "        similarity = 1 - cosine(fingerprint1, fingerprint2)\n",
    "        are_duplicates = similarity > threshold\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "        print(f\"Similarity score: {similarity}\")\n",
    "        print(f\"Result: The two files are {'near duplicates' if are_duplicates else 'not near duplicates'}.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "\n",
    "print(f\"\\nTested files:\")\n",
    "print(f\"File 1: {file_paths[0]}\")\n",
    "print(f\"File 2: {file_paths[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply duplicate checking to all files\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# duplicates, discarded_files = check_and_remove_duplicates('Converted Recordings')\n",
    "\n",
    "# print(f\"Duplicate files found: {len(duplicates)}\")\n",
    "# print(\"List of duplicate files:\")\n",
    "# for file in duplicates:\n",
    "#     print(file)\n",
    "\n",
    "# print(f\"\\nTotal discarded files: {len(discarded_files)}\")\n",
    "# print(\"List of discarded files and reasons:\")\n",
    "# for file, reason in discarded_files:\n",
    "#     print(f\"{file}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(file_path, shared_discarded_files, target_length=5, overlap=0.5, target_sr=44100):\n",
    "    try:\n",
    "        # Load and clean the audio\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        audio = clean_audio(audio, sr, file_path, shared_discarded_files)\n",
    "        if audio is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Check if audio is shorter than 4410 samples (100ms at 44.1kHz)\n",
    "        if len(audio) < 4410:\n",
    "            shared_discarded_files.append((file_path, 'too_short'))\n",
    "            return None, None\n",
    "            \n",
    "        # Convert target_length to samples\n",
    "        target_samples = sr * target_length\n",
    "        \n",
    "        # If audio is shorter than target length, pad with zeros\n",
    "        if len(audio) < target_samples:\n",
    "            # Use np.pad instead of librosa.util.fix_length\n",
    "            audio = np.pad(audio, (0, target_samples - len(audio)))\n",
    "        \n",
    "        # If audio is longer than target length, segment with overlap\n",
    "        else:\n",
    "            segments = []\n",
    "            for start in range(0, len(audio), int(target_samples * (1 - overlap))):\n",
    "                segment = audio[start:start + target_samples]\n",
    "                if len(segment) == target_samples:\n",
    "                    segments.append(segment)\n",
    "                elif len(segment) > 0:  # Handle the last segment if it's shorter\n",
    "                    # Use np.pad for the last segment as well\n",
    "                    segment = np.pad(segment, (0, target_samples - len(segment)))\n",
    "                    segments.append(segment)\n",
    "            audio = np.array(segments)\n",
    "\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {file_path}: {str(e)}\")\n",
    "        shared_discarded_files.append((file_path, f'error: {str(e)}'))\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(args):\n",
    "    row, audio_dir, output_dir, shared_duplicates, shared_discarded_files = args\n",
    "    file_path = os.path.join(audio_dir, row['file_name'])\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.warning(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    processed_audio, sr = process_audio(file_path, shared_duplicates, shared_discarded_files)\n",
    "    if processed_audio is None:\n",
    "        return None\n",
    "    \n",
    "    processed_data = []\n",
    "    if processed_audio.ndim == 2:\n",
    "        for i, segment in enumerate(processed_audio):\n",
    "            new_row = row.copy()\n",
    "            base_filename = f\"{os.path.splitext(row['file_name'])[0]}_segment_{i}\"\n",
    "            new_row['processed_file'] = f\"{base_filename}.wav\"\n",
    "            wavfile.write(os.path.join(output_dir, new_row['processed_file']), sr, segment)\n",
    "            processed_data.append(new_row)\n",
    "    else:\n",
    "        base_filename = f\"{os.path.splitext(row['file_name'])[0]}_processed\"\n",
    "        row['processed_file'] = f\"{base_filename}.wav\"\n",
    "        wavfile.write(os.path.join(output_dir, row['processed_file']), sr, processed_audio)\n",
    "        processed_data.append(row)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(converted_data, audio_dir, output_dir, n_processes=4):\n",
    "    manager = multiprocessing.Manager()\n",
    "    shared_duplicates = manager.list()\n",
    "    shared_discarded_files = manager.list()\n",
    "\n",
    "    with Pool(n_processes) as p:\n",
    "        results = list(tqdm(p.imap(\n",
    "            process_file, \n",
    "            [(row, audio_dir, output_dir, shared_duplicates, shared_discarded_files) \n",
    "             for _, row in converted_data.iterrows()]), \n",
    "            total=len(converted_data)))\n",
    "    \n",
    "    processed_data = [item for sublist in results if sublist is not None for item in sublist]\n",
    "\n",
    "    # Save discarded files to a DataFrame and export as CSV\n",
    "    discard_log_df = pd.DataFrame(list(shared_discarded_files), columns=['file_path', 'reason'])\n",
    "    discard_log_df.to_csv('discarded_audio_log.csv', index=False)\n",
    "\n",
    "    return pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing audio processing on file: Antrostomus_carolinensis_Brush_Creek_Township_near__West_Union_Adams_County_Ohio_939173.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error processing Converted Recordings\\Antrostomus_carolinensis_Brush_Creek_Township_near__West_Union_Adams_County_Ohio_939173.wav: '<' not supported between instances of 'int' and 'list'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio processed successfully.\n",
      "Processed audio shape: (20, 220500)\n",
      "Sample rate: 44100\n",
      "Error: process_file returned None\n",
      "\n",
      "No files were discarded.\n",
      "\n",
      "Audio processing test complete.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Manager\n",
    "\n",
    "## Testing on a single file\n",
    "# Select a random file\n",
    "random_file = random.choice(converted_data['file_name'])\n",
    "file_path = os.path.join('Converted Recordings', random_file)\n",
    "\n",
    "print(f\"Testing audio processing on file: {random_file}\")\n",
    "\n",
    "# Create a dummy row for testing\n",
    "test_row = pd.Series({'file_name': random_file})\n",
    "\n",
    "# Create necessary directories\n",
    "output_dir = 'Test_Processed_Recordings'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create shared lists for multiprocessing simulation\n",
    "manager = Manager()\n",
    "shared_duplicates = manager.list()\n",
    "shared_discarded_files = manager.list()\n",
    "\n",
    "# Process the audio file\n",
    "processed_audio, sr = process_audio(file_path, shared_discarded_files)\n",
    "\n",
    "if processed_audio is not None:\n",
    "    print(f\"Audio processed successfully.\")\n",
    "    print(f\"Processed audio shape: {processed_audio.shape}\")\n",
    "    print(f\"Sample rate: {sr}\")\n",
    "\n",
    "    # Simulate the process_file function\n",
    "    args = (test_row, 'Converted Recordings', output_dir, shared_duplicates, shared_discarded_files)\n",
    "    processed_data = process_file(args)\n",
    "\n",
    "    if processed_data is not None:\n",
    "        print(\"\\nProcessed data:\")\n",
    "        for item in processed_data:\n",
    "            print(f\"Processed file: {item['processed_file']}\")\n",
    "            print(f\"Number of segments: {len(processed_data)}\")\n",
    "\n",
    "        # Verify the output files\n",
    "        for item in processed_data:\n",
    "            output_file = os.path.join(output_dir, item['processed_file'])\n",
    "            if os.path.exists(output_file):\n",
    "                print(f\"Output file created: {output_file}\")\n",
    "                # Load and print some information about the output file\n",
    "                audio, sr = librosa.load(output_file, sr=None)\n",
    "                print(f\"Output audio duration: {librosa.get_duration(y=audio, sr=sr):.2f} seconds\")\n",
    "            else:\n",
    "                print(f\"Error: Output file not created: {output_file}\")\n",
    "    else:\n",
    "        print(\"Error: process_file returned None\")\n",
    "else:\n",
    "    print(\"Error: Audio processing failed\")\n",
    "\n",
    "# Check for any discarded files\n",
    "if shared_discarded_files:\n",
    "    print(\"\\nDiscarded files:\")\n",
    "    for file_path, reason in shared_discarded_files:\n",
    "        print(f\"{file_path}: {reason}\")\n",
    "else:\n",
    "    print(\"\\nNo files were discarded.\")\n",
    "\n",
    "print(\"\\nAudio processing test complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/689 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "processed_dir = 'Processed Recordings'\n",
    "processed_data = process_dataset(converted_data, converted_dir, processed_dir)\n",
    "print('Audio Processing Complete')\n",
    "\n",
    "# Print completion message and count files in Processed Recordings directory\n",
    "processed_file_count = len([f for f in os.listdir(processed_dir) if f.endswith('.wav')])\n",
    "print(f\"\\nAudio processing is complete. There are now {processed_file_count} files in the '{processed_dir}' directory.\")\n",
    "\n",
    "# Output discarded files\n",
    "discard_log_df = pd.read_csv('discarded_audio_log.csv')\n",
    "if not discard_log_df.empty:\n",
    "    print(\"\\nThe following files were discarded:\")\n",
    "    for _, row in discard_log_df.iterrows():\n",
    "        print(f\"{row['file_path']}: {row['reason']}\")\n",
    "else:\n",
    "    print(\"\\nNo files were discarded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(processed_data.info())\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "### Augment the processed audio files.\n",
    "- Pitch Shift\n",
    "- Time Stretch\n",
    "- add_noise\n",
    "- change_speed\n",
    "- apply_filter\n",
    "- add_background\n",
    "- time_shift\n",
    "- augment_audio\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m sr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m44100\u001b[39m\n\u001b[0;32m     30\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m---> 31\u001b[0m nature_background \u001b[38;5;241m=\u001b[39m \u001b[43mmix_nature_sounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m, in \u001b[0;36mmix_nature_sounds\u001b[1;34m(duration, sr)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmix_nature_sounds\u001b[39m(duration, sr):\n\u001b[1;32m---> 21\u001b[0m     wind \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_wind_sound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     leaf \u001b[38;5;241m=\u001b[39m generate_leaf_rustle(duration, sr)\n\u001b[0;32m     23\u001b[0m     water \u001b[38;5;241m=\u001b[39m generate_water_sound(duration, sr)\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m, in \u001b[0;36mgenerate_wind_sound\u001b[1;34m(duration, sr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_wind_sound\u001b[39m(duration, sr):\n\u001b[1;32m----> 2\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, duration, \u001b[38;5;28mint\u001b[39m(sr \u001b[38;5;241m*\u001b[39m duration), \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m     wind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;28mint\u001b[39m(sr \u001b[38;5;241m*\u001b[39m duration))\n\u001b[0;32m      4\u001b[0m     wind_filtered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconvolve(wind, np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_wind_sound(duration, sr):\n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    wind = np.random.normal(0, 0.1, int(sr * duration))\n",
    "    wind_filtered = np.convolve(wind, np.ones(1000)/1000, mode='same')\n",
    "    return wind_filtered / np.max(np.abs(wind_filtered))\n",
    "\n",
    "def generate_leaf_rustle(duration, sr):\n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    leaf = np.random.normal(0, 0.1, int(sr * duration))\n",
    "    envelope = np.exp(-t * 10) * np.sin(2 * np.pi * 2 * t)**2\n",
    "    return leaf * envelope / np.max(np.abs(leaf * envelope))\n",
    "\n",
    "def generate_water_sound(duration, sr):\n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    water = np.random.normal(0, 0.1, int(sr * duration))\n",
    "    water_filtered = np.convolve(water, np.ones(500)/500, mode='same')\n",
    "    ripple = np.sin(2 * np.pi * 2 * t) * np.exp(-t * 2)\n",
    "    return (water_filtered + ripple) / np.max(np.abs(water_filtered + ripple))\n",
    "\n",
    "def mix_nature_sounds(duration, sr):\n",
    "    wind = generate_wind_sound(duration, sr)\n",
    "    leaf = generate_leaf_rustle(duration, sr)\n",
    "    water = generate_water_sound(duration, sr)\n",
    "    \n",
    "    mix = wind * 0.7 + leaf * 0.2 + water * 0.1\n",
    "    return mix / np.max(np.abs(mix))\n",
    "\n",
    "# Generate a 5-second mix of nature-like sounds\n",
    "sr = 44100\n",
    "duration = 5\n",
    "nature_background = mix_nature_sounds(duration, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pitch_shift(audio, sr, n_steps):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def time_stretch(audio, rate):\n",
    "    return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "def add_noise(audio, noise_factor):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    augmented_audio = audio + noise_factor * noise\n",
    "    return np.clip(augmented_audio, -1, 1)\n",
    "\n",
    "def change_speed(audio, speed_factor):\n",
    "    return librosa.effects.time_stretch(audio, rate=1/speed_factor)\n",
    "\n",
    "def apply_filter(audio, sr, filter_type='lowpass', cutoff=1000):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(4, normal_cutoff, btype=filter_type, analog=False)\n",
    "    return lfilter(b, a, audio)\n",
    "\n",
    "def add_background(audio, background, ratio=0.1):\n",
    "    if len(background) > len(audio):\n",
    "        start = np.random.randint(0, len(background) - len(audio))\n",
    "        background = background[start:start+len(audio)]\n",
    "    else:\n",
    "        background = np.pad(background, (0, max(0, len(audio) - len(background))))\n",
    "    return audio + ratio * background\n",
    "\n",
    "def time_shift(audio, shift_max, roll_prob=0.5):\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    if random.random() < roll_prob:\n",
    "        return np.roll(audio, shift)\n",
    "    else:\n",
    "        if shift > 0:\n",
    "            return np.pad(audio, (shift, 0))[:len(audio)]\n",
    "        else:\n",
    "            return np.pad(audio, (0, -shift))[:-shift]\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    augmentations = [\n",
    "        (pitch_shift, {'n_steps': random.uniform(-2, 2)}),\n",
    "        (time_stretch, {'rate': random.uniform(0.8, 1.2)}),\n",
    "        (add_noise, {'noise_factor': random.uniform(0.001, 0.015)}),\n",
    "        (change_speed, {'speed_factor': random.uniform(0.9, 1.1)}),\n",
    "        (apply_filter, {'filter_type': random.choice(['lowpass', 'highpass']),\n",
    "                        'cutoff': random.uniform(1000, 4000)}),\n",
    "        (time_shift, {'shift_max': int(sr * 0.5)})\n",
    "    ]\n",
    "    \n",
    "    # Randomly select 2-4 augmentations\n",
    "    num_augments = random.randint(2, 4)\n",
    "    selected_augments = random.sample(augmentations, num_augments)\n",
    "    \n",
    "    applied_augmentations = []\n",
    "    \n",
    "    # Apply selected augmentations\n",
    "    for augment_func, params in selected_augments:\n",
    "        audio = augment_func(audio, sr, **params)\n",
    "        applied_augmentations.append(f\"{augment_func.__name__}:{','.join(f'{k}={v}' for k, v in params.items())}\")\n",
    "    \n",
    "    # Add synthesized nature background\n",
    "    if random.random() < 0.5:\n",
    "        nature_background = mix_nature_sounds(len(audio) / sr, sr)\n",
    "        ratio = random.uniform(0.1, 0.3)\n",
    "        audio = add_background(audio, nature_background, ratio=ratio)\n",
    "        applied_augmentations.append(f\"add_background:ratio={ratio:.2f}\")\n",
    "    \n",
    "    return audio, applied_augmentations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete. 0 new samples created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def augment_and_save(input_file, output_dir, num_augmentations=3):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(input_file, sr=None)\n",
    "        \n",
    "        augmented_files = []\n",
    "        all_applied_augmentations = []\n",
    "        \n",
    "        for i in range(num_augmentations):\n",
    "            # Apply augmentation\n",
    "            augmented_audio, applied_augmentations = augment_audio(audio, sr)\n",
    "            \n",
    "            # Generate new filename\n",
    "            base_name = os.path.basename(input_file)\n",
    "            name, ext = os.path.splitext(base_name)\n",
    "            new_name = f\"{name}_aug_{i+1}{ext}\"\n",
    "            output_path = os.path.join(output_dir, new_name)\n",
    "            \n",
    "            # Save augmented audio\n",
    "            sf.write(output_path, augmented_audio, sr)\n",
    "            \n",
    "            augmented_files.append(output_path)\n",
    "            all_applied_augmentations.append(';'.join(applied_augmentations))\n",
    "        \n",
    "        return augmented_files, all_applied_augmentations\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_file}: {str(e)}\")\n",
    "        return [], []\n",
    "\n",
    "\n",
    "def process_dataframe(df, input_dir, output_dir, num_augmentations=3):\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing files\"):\n",
    "        input_file = os.path.join(input_dir, row['file_path'])\n",
    "        augmented_files, augmentations = augment_and_save(input_file, output_dir, num_augmentations)\n",
    "        \n",
    "        for aug_file, aug_details in zip(augmented_files, augmentations):\n",
    "            new_row = row.copy()\n",
    "            new_row['file_path'] = os.path.relpath(aug_file, output_dir)\n",
    "            new_row['augmentations'] = aug_details\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    augmented_df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    return augmented_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test Augmentation functions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Select a random file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m random_file \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[43mprocessed_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed Recordings\u001b[39m\u001b[38;5;124m'\u001b[39m, random_file)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'processed_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Augmentation functions\n",
    "\n",
    "# Select a random file\n",
    "random_file = random.choice(processed_data['file_name'])\n",
    "file_path = os.path.join('Processed Recordings', random_file)\n",
    "\n",
    "# Load the audio file\n",
    "audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "# List of augmentation functions to test\n",
    "augmentation_functions = [\n",
    "    (pitch_shift, {'n_steps': 2}),\n",
    "    (time_stretch, {'rate': 1.2}),\n",
    "    (add_noise, {'noise_factor': 0.01}),\n",
    "    (change_speed, {'speed_factor': 1.1}),\n",
    "    (apply_filter, {'filter_type': 'lowpass', 'cutoff': 2000}),\n",
    "    (time_shift, {'shift_max': int(sr * 0.5)}),\n",
    "    (mix_nature_sounds, {'duration': len(audio) / sr})\n",
    "]\n",
    "\n",
    "print(f\"Testing augmentations on file: {random_file}\")\n",
    "\n",
    "# Apply each augmentation function and save the result\n",
    "for i, (func, params) in enumerate(augmentation_functions):\n",
    "    if func.__name__ == 'mix_nature_sounds':\n",
    "        # For mix_nature_sounds, we need to handle it differently\n",
    "        background = func(**params)\n",
    "        augmented = add_background(audio, background, ratio=0.2)\n",
    "    else:\n",
    "        # For other functions, apply them directly\n",
    "        augmented = func(audio, sr, **params)\n",
    "    \n",
    "    # Generate output filename\n",
    "    base_name = os.path.splitext(random_file)[0]\n",
    "    output_file = f\"{base_name}_aug_{func.__name__}.wav\"\n",
    "    output_path = os.path.join('Augmented Recordings', output_file)\n",
    "    \n",
    "    # Save the augmented audio\n",
    "    sf.write(output_path, augmented, sr)\n",
    "    \n",
    "    print(f\"Applied {func.__name__}, saved as {output_file}\")\n",
    "\n",
    "print(\"Augmentation test complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply augmentation to every file\n",
    "input_dir = 'Processed Recordings'\n",
    "output_dir = 'Augmented Recordings'\n",
    "num_augmentations = 3\n",
    "\n",
    "\n",
    "# Process the dataframe\n",
    "augmented_data = process_dataframe(processed_data, input_dir, output_dir, num_augmentations)\n",
    "\n",
    "print(f\"Augmentation complete. {len(augmented_data) - len(processed_data)} new samples created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from the processed and augmented audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_df\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m, in \u001b[0;36mfilter_dataset\u001b[1;34m(df, keep_dirs)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(dir_name \u001b[38;5;129;01min\u001b[39;00m file_path \u001b[38;5;28;01mfor\u001b[39;00m dir_name \u001b[38;5;129;01min\u001b[39;00m keep_dirs_set)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Filter the dataframe\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: is_keep_dir(x))]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Reset the index of the filtered dataframe\u001b[39;00m\n\u001b[0;32m     14\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'file_path'"
     ]
    }
   ],
   "source": [
    "# Drop original recordings from dataset for feature extraction\n",
    "def filter_dataset(df, keep_dirs=['Processed Recordings', 'Augmented Recordings']):\n",
    "    # Convert keep_dirs to a set for faster lookup\n",
    "    keep_dirs_set = set(keep_dirs)\n",
    "    \n",
    "    # Function to check if a file path is in one of the keep_dirs\n",
    "    def is_keep_dir(file_path):\n",
    "        return any(dir_name in file_path for dir_name in keep_dirs_set)\n",
    "    \n",
    "    # Filter the dataframe\n",
    "    filtered_df = df[df['file_path'].apply(lambda x: is_keep_dir(x))]\n",
    "    \n",
    "    # Reset the index of the filtered dataframe\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    \n",
    "    # Print some information about the filtering process\n",
    "    print(f\"Original dataset size: {len(df)}\")\n",
    "    print(f\"Filtered dataset size: {len(filtered_df)}\")\n",
    "    print(f\"Removed {len(df) - len(filtered_df)} entries\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Usage\n",
    "filtered_data = filter_dataset(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(audio, sr):\n",
    "    # Mel-spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    \n",
    "    # Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    \n",
    "    # Spectral Rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    \n",
    "    return {\n",
    "        'mel_spectrogram_db': mel_spec_db,\n",
    "        'mfccs': mfccs,\n",
    "        'spectral_centroids': spectral_centroids,\n",
    "        'chroma': chroma,\n",
    "        'zero_crossing_rate': zero_crossing_rate,\n",
    "        'spectral_rolloff': spectral_rolloff\n",
    "    }\n",
    "\n",
    "def summarize_feature(feature):\n",
    "    if feature.ndim == 1:\n",
    "        return [np.mean(feature), np.std(feature), np.max(feature)]\n",
    "    elif feature.ndim == 2:\n",
    "        return np.hstack([\n",
    "            np.mean(feature, axis=1),\n",
    "            np.std(feature, axis=1),\n",
    "            np.max(feature, axis=1)\n",
    "        ])\n",
    "    \n",
    "def save_mel_spectrogram(mel_spec, output_dir, base_filename, sr):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spec, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{base_filename}_mel_spectrogram.png\"))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(file_path, output_dir):\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=sr)\n",
    "        features = extract_features(audio, sr)\n",
    "        \n",
    "        # Summarize features\n",
    "        feature_summary = {}\n",
    "        for key, value in features.items():\n",
    "            if key != 'mel_spectrogram':\n",
    "                feature_summary[f\"{key}_summary\"] = summarize_feature(value)\n",
    "        \n",
    "        # Create feature vector\n",
    "        feature_vector = np.hstack([\n",
    "            feature_summary.get('mfccs_summary', np.array([])),\n",
    "            feature_summary.get('spectral_centroids_summary', np.array([])),\n",
    "            feature_summary.get('chroma_summary', np.array([])),\n",
    "            feature_summary.get('zero_crossing_rate_summary', np.array([])),\n",
    "            feature_summary.get('spectral_rolloff_summary', np.array([]))\n",
    "            ])\n",
    "        \n",
    "        # Save mel-spectrogram as image\n",
    "        base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        save_mel_spectrogram(features['mel_spectrogram'], output_dir, base_filename)\n",
    "        \n",
    "        return feature_vector, features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Main processing loop\n",
    "def process_audio_files(filtered_data, output_dir):\n",
    "    feature_data = []\n",
    "    \n",
    "    for _, row in tqdm(filtered_data.iterrows(), total=len(filtered_data)):\n",
    "        file_path = row['file_name']\n",
    "        feature_vector, full_features = process_audio_file(file_path, output_dir)\n",
    "        \n",
    "        if feature_vector is not None and full_features is not None:\n",
    "            feature_dict = {\n",
    "                'file_name': file_path,\n",
    "                'feature_vector': feature_vector,\n",
    "            }\n",
    "            \n",
    "            # Add full feature arrays\n",
    "            for key, value in full_features.items():\n",
    "                feature_dict[f\"{key}_full\"] = value\n",
    "            \n",
    "            feature_data.append(feature_dict)\n",
    "    \n",
    "    return feature_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select a random file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m random_file \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[43mfiltered_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed Recordings\u001b[39m\u001b[38;5;124m'\u001b[39m, random_file)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Select a random file\n",
    "random_file = random.choice(filtered_data['file_name'])\n",
    "file_path = os.path.join('Processed Recordings', random_file)\n",
    "\n",
    "# Load the audio file\n",
    "audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "print(f\"Testing feature extraction on file: {random_file}\")\n",
    "\n",
    "# Extract features\n",
    "features = extract_features(audio, sr)\n",
    "\n",
    "# Print a summary of each feature\n",
    "for feature_name, feature_data in features.items():\n",
    "    if feature_name == 'mel_spectrogram_db':\n",
    "        print(f\"{feature_name} shape: {feature_data.shape}\")\n",
    "    else:\n",
    "        print(f\"{feature_name} shape: {feature_data.shape}, mean: {np.mean(feature_data):.4f}, std: {np.std(feature_data):.4f}\")\n",
    "\n",
    "# Summarize features\n",
    "feature_summary = {}\n",
    "for key, value in features.items():\n",
    "    if key != 'mel_spectrogram_db':\n",
    "        feature_summary[f\"{key}_summary\"] = summarize_feature(value)\n",
    "\n",
    "# Print summary of summarized features\n",
    "print(\"\\nSummarized Features:\")\n",
    "for key, value in feature_summary.items():\n",
    "    print(f\"{key} shape: {value.shape}, mean: {np.mean(value):.4f}, std: {np.std(value):.4f}\")\n",
    "\n",
    "# Create feature vector\n",
    "feature_vector = np.hstack([\n",
    "    feature_summary.get('mfccs_summary', np.array([])),\n",
    "    feature_summary.get('spectral_centroids_summary', np.array([])),\n",
    "    feature_summary.get('chroma_summary', np.array([])),\n",
    "    feature_summary.get('zero_crossing_rate_summary', np.array([])),\n",
    "    feature_summary.get('spectral_rolloff_summary', np.array([]))\n",
    "])\n",
    "\n",
    "print(f\"\\nFinal feature vector shape: {feature_vector.shape}\")\n",
    "\n",
    "# Save mel-spectrogram as image\n",
    "output_dir = 'test_mel_spectrograms'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "save_mel_spectrogram(features['mel_spectrogram_db'], output_dir, base_filename, sr)\n",
    "\n",
    "print(f\"Mel-spectrogram saved as: {base_filename}_mel_spectrogram.png in {output_dir}\")\n",
    "\n",
    "print(\"Feature extraction test complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_audio_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply feature extraction to every file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmel-spectrograms\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m final_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_audio_files\u001b[49m(filtered_data, output_dir)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m: item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m'\u001b[39m: item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m final_data])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_audio_files' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply feature extraction to every file\n",
    "output_dir = 'mel-spectrograms'\n",
    "final_data = process_audio_files(filtered_data, output_dir)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame([{'file_name': item['file_name'], 'feature_vector': item['feature_vector']} for item in final_data])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"quality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "df.to_csv('final_data.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Summary data saved to 'final_data.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
