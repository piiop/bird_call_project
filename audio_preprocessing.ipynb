{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "# Data processing and scientific computing\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing\n",
    "    - Remove low-quality or noisy recordings based on metadata if available, or by manually inspecting a few samples.\n",
    "\t    - It's a good idea to manually inspect some of the longer clips, especially outliers.\n",
    "\t    - - Listen for: a) Consistency of the bird call throughout the clip b) Presence of long periods of silence c) Sudden changes in background noise or environment\n",
    "\t\t- If you find issues, you might consider trimming these clips to the most relevant sections before segmenting.\n",
    "\t\t- - Definitely inspect a sample of low-rated files.\n",
    "\t\t- Listen for: a) Clarity of the bird call b) Signal-to-noise ratio (how clear the bird call is compared to background noise) c) Presence of distortions or artifacts\n",
    "\t\t- Consider setting a threshold for the quality rating, below which you might exclude files from your dataset.\n",
    "\t\t- Determining if a file is too \"noisy\":\n",
    "\n",
    "\t\t- This can be subjective, but here are some approaches: a) Signal-to-Noise Ratio (SNR): Calculate the SNR for each file. Files below a certain threshold could be considered too noisy. b) Spectral analysis: Look at the spectrogram. A very noisy file will have a lot of energy spread across all frequencies. c) Perceptual evaluation: Listen to a sample and rate them yourself. This can help you calibrate your automatic methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ohio_bird_recordings_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "A           267\n",
       "B           261\n",
       "C           147\n",
       "D            48\n",
       "no score     16\n",
       "E             6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~((data['common_name'] == 'Identity unknown') & (data['species'] == 'mystery'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>common_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>length</th>\n",
       "      <th>quality</th>\n",
       "      <th>remarks</th>\n",
       "      <th>sex</th>\n",
       "      <th>stage</th>\n",
       "      <th>also</th>\n",
       "      <th>file_name</th>\n",
       "      <th>local_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>678953</td>\n",
       "      <td>Vireo</td>\n",
       "      <td>bellii</td>\n",
       "      <td>Bell's Vireo</td>\n",
       "      <td>39.20950</td>\n",
       "      <td>-84.78210</td>\n",
       "      <td>song</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>17:40</td>\n",
       "      <td>0:03</td>\n",
       "      <td>E</td>\n",
       "      <td>Originally recorded as a video and uploaded to...</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vireo_bellii_Whitewater_Township_near__Harriso...</td>\n",
       "      <td>Original Recordings\\Vireo_bellii_Whitewater_To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>376462</td>\n",
       "      <td>Baeolophus</td>\n",
       "      <td>bicolor</td>\n",
       "      <td>Tufted Titmouse</td>\n",
       "      <td>40.94200</td>\n",
       "      <td>-81.52360</td>\n",
       "      <td>call</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>07:00</td>\n",
       "      <td>0:15</td>\n",
       "      <td>no score</td>\n",
       "      <td>Odd call from a Tufted Titmouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Corvus brachyrhynchos</td>\n",
       "      <td>Baeolophus_bicolor_Ohio_near__Akron_Summit_Cou...</td>\n",
       "      <td>Original Recordings\\Baeolophus_bicolor_Ohio_ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>475639</td>\n",
       "      <td>Tachycineta</td>\n",
       "      <td>bicolor</td>\n",
       "      <td>Tree Swallow</td>\n",
       "      <td>41.96820</td>\n",
       "      <td>-82.53050</td>\n",
       "      <td>call</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>5:29</td>\n",
       "      <td>0:02</td>\n",
       "      <td>no score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tachycineta_bicolor_Pelee_near__Leamington_Ess...</td>\n",
       "      <td>Original Recordings\\Tachycineta_bicolor_Pelee_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>17172</td>\n",
       "      <td>Spizella</td>\n",
       "      <td>passerina</td>\n",
       "      <td>Chipping Sparrow</td>\n",
       "      <td>41.93338</td>\n",
       "      <td>-83.54994</td>\n",
       "      <td>song</td>\n",
       "      <td>2007-07-16</td>\n",
       "      <td>?</td>\n",
       "      <td>0:28</td>\n",
       "      <td>E</td>\n",
       "      <td>Two birds singing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zenaida macroura</td>\n",
       "      <td>Spizella_passerina_Michigan_Monroe_County_1717...</td>\n",
       "      <td>Original Recordings\\Spizella_passerina_Michiga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>554398</td>\n",
       "      <td>Spizella</td>\n",
       "      <td>pusilla</td>\n",
       "      <td>Field Sparrow</td>\n",
       "      <td>39.88880</td>\n",
       "      <td>-82.79780</td>\n",
       "      <td>song</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>15:30</td>\n",
       "      <td>0:20</td>\n",
       "      <td>no score</td>\n",
       "      <td>Habitat was mostly open field / wetlands, with...</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spizella_pusilla_Madison_Township_near__Canal_...</td>\n",
       "      <td>Original Recordings\\Spizella_pusilla_Madison_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>17143</td>\n",
       "      <td>Melospiza</td>\n",
       "      <td>melodia</td>\n",
       "      <td>Song Sparrow</td>\n",
       "      <td>41.93338</td>\n",
       "      <td>-83.54994</td>\n",
       "      <td>song</td>\n",
       "      <td>2007-07-18</td>\n",
       "      <td>?</td>\n",
       "      <td>0:34</td>\n",
       "      <td>E</td>\n",
       "      <td>Traffic noise in background.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quiscalus quiscula, Passer domesticus</td>\n",
       "      <td>Melospiza_melodia_Michigan_Monroe_County_17143...</td>\n",
       "      <td>Original Recordings\\Melospiza_melodia_Michigan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>374227</td>\n",
       "      <td>Geothlypis</td>\n",
       "      <td>trichas</td>\n",
       "      <td>Common Yellowthroat</td>\n",
       "      <td>41.18950</td>\n",
       "      <td>-81.57810</td>\n",
       "      <td>song</td>\n",
       "      <td>2017-06-07</td>\n",
       "      <td>07:30</td>\n",
       "      <td>0:30</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melanerpes carolinus, Contopus virens, Baeolop...</td>\n",
       "      <td>Geothlypis_trichas_Ohio_near__Peninsula_Summit...</td>\n",
       "      <td>Original Recordings\\Geothlypis_trichas_Ohio_ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>560021</td>\n",
       "      <td>Sonus</td>\n",
       "      <td>naturalis</td>\n",
       "      <td>Soundscape</td>\n",
       "      <td>41.43300</td>\n",
       "      <td>-81.41800</td>\n",
       "      <td>song</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>14:45</td>\n",
       "      <td>0:28</td>\n",
       "      <td>no score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sonus_naturalis_Chagrin_Falls_Township_near__M...</td>\n",
       "      <td>Original Recordings\\Sonus_naturalis_Chagrin_Fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        genus    species          common_name  latitude  longitude  \\\n",
       "177  678953        Vireo     bellii         Bell's Vireo  39.20950  -84.78210   \n",
       "192  376462   Baeolophus    bicolor      Tufted Titmouse  40.94200  -81.52360   \n",
       "221  475639  Tachycineta    bicolor         Tree Swallow  41.96820  -82.53050   \n",
       "358   17172     Spizella  passerina     Chipping Sparrow  41.93338  -83.54994   \n",
       "359  554398     Spizella    pusilla        Field Sparrow  39.88880  -82.79780   \n",
       "389   17143    Melospiza    melodia         Song Sparrow  41.93338  -83.54994   \n",
       "553  374227   Geothlypis    trichas  Common Yellowthroat  41.18950  -81.57810   \n",
       "676  560021        Sonus  naturalis           Soundscape  41.43300  -81.41800   \n",
       "\n",
       "     type        date   time length   quality  \\\n",
       "177  song  2015-06-02  17:40   0:03         E   \n",
       "192  call  2017-06-21  07:00   0:15  no score   \n",
       "221  call  2019-05-17   5:29   0:02  no score   \n",
       "358  song  2007-07-16      ?   0:28         E   \n",
       "359  song  2020-05-03  15:30   0:20  no score   \n",
       "389  song  2007-07-18      ?   0:34         E   \n",
       "553  song  2017-06-07  07:30   0:30         E   \n",
       "676  song  2020-05-20  14:45   0:28  no score   \n",
       "\n",
       "                                               remarks        sex      stage  \\\n",
       "177  Originally recorded as a video and uploaded to...       male      adult   \n",
       "192                    Odd call from a Tufted Titmouse        NaN        NaN   \n",
       "221                                                NaN        NaN        NaN   \n",
       "358                                  Two birds singing        NaN        NaN   \n",
       "359  Habitat was mostly open field / wetlands, with...  uncertain  uncertain   \n",
       "389                       Traffic noise in background.        NaN        NaN   \n",
       "553                                                NaN        NaN        NaN   \n",
       "676                                                NaN  uncertain  uncertain   \n",
       "\n",
       "                                                  also  \\\n",
       "177                                                NaN   \n",
       "192                              Corvus brachyrhynchos   \n",
       "221                                                NaN   \n",
       "358                                   Zenaida macroura   \n",
       "359                                                NaN   \n",
       "389              Quiscalus quiscula, Passer domesticus   \n",
       "553  Melanerpes carolinus, Contopus virens, Baeolop...   \n",
       "676                                                NaN   \n",
       "\n",
       "                                             file_name  \\\n",
       "177  Vireo_bellii_Whitewater_Township_near__Harriso...   \n",
       "192  Baeolophus_bicolor_Ohio_near__Akron_Summit_Cou...   \n",
       "221  Tachycineta_bicolor_Pelee_near__Leamington_Ess...   \n",
       "358  Spizella_passerina_Michigan_Monroe_County_1717...   \n",
       "359  Spizella_pusilla_Madison_Township_near__Canal_...   \n",
       "389  Melospiza_melodia_Michigan_Monroe_County_17143...   \n",
       "553  Geothlypis_trichas_Ohio_near__Peninsula_Summit...   \n",
       "676  Sonus_naturalis_Chagrin_Falls_Township_near__M...   \n",
       "\n",
       "                                            local_file  \n",
       "177  Original Recordings\\Vireo_bellii_Whitewater_To...  \n",
       "192  Original Recordings\\Baeolophus_bicolor_Ohio_ne...  \n",
       "221  Original Recordings\\Tachycineta_bicolor_Pelee_...  \n",
       "358  Original Recordings\\Spizella_passerina_Michiga...  \n",
       "359  Original Recordings\\Spizella_pusilla_Madison_T...  \n",
       "389  Original Recordings\\Melospiza_melodia_Michigan...  \n",
       "553  Original Recordings\\Geothlypis_trichas_Ohio_ne...  \n",
       "676  Original Recordings\\Sonus_naturalis_Chagrin_Fa...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "low_quality_files = data[(data['quality'] == 'E') | (data['quality'] == 'no score')]\n",
    "display(low_quality_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert mp3 to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_mp3_to_wav(mp3_path, wav_path):\n",
    "    \"\"\"\n",
    "    Convert an MP3 file to WAV format using librosa and soundfile.\n",
    "    \n",
    "    Args:\n",
    "    mp3_path (str): Path to the input MP3 file\n",
    "    wav_path (str): Path to save the output WAV file\n",
    "    \n",
    "    Returns:\n",
    "    str: Path to the created WAV file\n",
    "    \"\"\"\n",
    "    # Load the mp3 file\n",
    "    audio, sr = librosa.load(mp3_path, sr=None, mono=False)\n",
    "    \n",
    "    # Save as wav\n",
    "    sf.write(wav_path, audio.T, sr)\n",
    "    \n",
    "    return wav_path\n",
    "\n",
    "def batch_convert_to_wav(data, input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Convert all MP3 files in the dataset to WAV format.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame containing file information\n",
    "    input_dir (str): Directory containing the input MP3 files\n",
    "    output_dir (str): Directory to save the output WAV files\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated DataFrame with new file paths\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    new_data = data.copy()\n",
    "    for index, row in new_data.iterrows():\n",
    "        mp3_path = os.path.join(input_dir, row['file_name'])\n",
    "        wav_filename = os.path.splitext(row['file_name'])[0] + '.wav'\n",
    "        wav_path = os.path.join(output_dir, wav_filename)\n",
    "        \n",
    "        convert_mp3_to_wav(mp3_path, wav_path)\n",
    "        new_data.at[index, 'file_name'] = wav_filename\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name\n",
       "Branta_canadensis_Whitewater_Township_near__Harrison_Hamilton_County_Ohio_726750.mp3    1\n",
       "Molothrus_ater_Pelee_near__Leamington_Essex_County_Ontario_476558.mp3                   1\n",
       "Agelaius_phoeniceus_Ross_Township_near__Hamilton_Butler_County_Ohio_533370.mp3          1\n",
       "Agelaius_phoeniceus_Crosby_Township_near__Harrison_Hamilton_County_Ohio_482675.mp3      1\n",
       "Agelaius_phoeniceus_Case_Farm_Gates_Mills_Ohio_98722.mp3                                1\n",
       "                                                                                       ..\n",
       "Progne_subis_Magee_Marsh_Ohio_164751.mp3                                                1\n",
       "Progne_subis_Magee_Marsh_Ohio_164748.mp3                                                1\n",
       "Progne_subis_Whitewater_Township_near__Cleves_Hamilton_County_Ohio_817716.mp3           1\n",
       "Hirundo_rustica_Green_Township_near__Cincinnati_Hamilton_County_Ohio_833706.mp3         1\n",
       "Sonus_naturalis_Maumee_Bay_State_Park_Lucas_County_Ohio_821133.mp3                      1\n",
       "Name: count, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['file_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting MP3 files to WAV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16148\\AppData\\Local\\Temp\\ipykernel_15484\\1298917807.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(mp3_path, sr=None, mono=False)\n",
      "c:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Original Recordings\\\\Colaptes_auratus_Miami_Township_near__North_Bend_Hamilton_County_Ohio_713588.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'Original Recordings\\\\Colaptes_auratus_Miami_Township_near__North_Bend_Hamilton_County_Ohio_713588.mp3': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert the MP3 files to WAV\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting MP3 files to WAV...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_convert_to_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion complete. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(converted_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files converted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 40\u001b[0m, in \u001b[0;36mbatch_convert_to_wav\u001b[1;34m(data, input_dir, output_dir)\u001b[0m\n\u001b[0;32m     37\u001b[0m     wav_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m     wav_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, wav_filename)\n\u001b[1;32m---> 40\u001b[0m     \u001b[43mconvert_mp3_to_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     new_data\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m wav_filename\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_data\n",
      "Cell \u001b[1;32mIn[26], line 13\u001b[0m, in \u001b[0;36mconvert_mp3_to_wav\u001b[1;34m(mp3_path, wav_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mConvert an MP3 file to WAV format using librosa and soundfile.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mstr: Path to the created WAV file\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load the mp3 file\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Save as wav\u001b[39;00m\n\u001b[0;32m     16\u001b[0m sf\u001b[38;5;241m.\u001b[39mwrite(wav_path, audio\u001b[38;5;241m.\u001b[39mT, sr)\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\librosa\\core\\audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Original Recordings\\\\Colaptes_auratus_Miami_Township_near__North_Bend_Hamilton_County_Ohio_713588.mp3'"
     ]
    }
   ],
   "source": [
    "original_dir = 'Original Recordings'\n",
    "converted_dir = 'Converted Recordings'\n",
    "\n",
    "# Convert the MP3 files to WAV\n",
    "print(\"Converting MP3 files to WAV...\")\n",
    "converted_data = batch_convert_to_wav(data, original_dir, converted_dir)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Conversion complete. {len(converted_data)} files converted.\")\n",
    "print(f\"WAV files saved in: {converted_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to the low quality and no score graded files.\n",
    "1 - bad\n",
    "2 - fine\n",
    "3 - fine\n",
    "4 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Audio Cleaning Functions\n",
    "\n",
    "These functions collectively clean an audio file by:\n",
    "1. Calculating its signal-to-noise ratio (SNR) and filtering out audio that is too noisy.\n",
    "2. Detecting and trimming long silences from the audio.\n",
    "3. Checking for spectral spread, which is an indicator of unwanted noise or anomalies.\n",
    "\n",
    "Main function:\n",
    "- `clean_audio`: Uses `is_too_noisy`, `has_long_silence`, and `check_spectral_spread` to decide if an audio file is suitable for further processing.\n",
    "\"\"\"\n",
    "\n",
    "- **Feature Extraction with Librosa**:\n",
    "    - Extract features like **Mel-spectrograms** and **MFCCs** from each audio file. These features are effective for audio classification tasks.\n",
    "    - Store these features as images (for CNN input) or numerical arrays (for models like Random Forest or RNNs).\n",
    "\n",
    "    - **Audio Standardization**:\n",
    "    - Convert all files to a consistent format (e.g., 16-bit WAV, mono-channel, and a sampling rate like 16 kHz).\n",
    "- **Clip Standardization**:\n",
    "    - Trim or pad each audio clip to a standard duration (e.g., 5 seconds), so all inputs have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snr(audio):\n",
    "    \"\"\"Calculate the signal-to-noise ratio of an audio clip.\"\"\"\n",
    "    signal = np.mean(audio**2)\n",
    "    noise = np.mean((audio - np.mean(audio))**2)\n",
    "    snr = 10 * np.log10(signal / noise)\n",
    "    return snr\n",
    "\n",
    "def is_too_noisy(audio, sr, threshold=-20):\n",
    "    \"\"\"Check if audio is too noisy based on its SNR.\"\"\"\n",
    "    snr = calculate_snr(audio)\n",
    "    return snr < threshold\n",
    "\n",
    "def has_long_silence(audio, sr, silence_threshold=-60, min_silence_duration=1.0):\n",
    "    \"\"\"Detects long silences within the audio clip.\"\"\"\n",
    "    intervals = librosa.effects.split(audio, top_db=-silence_threshold)\n",
    "    if len(intervals) > 1:\n",
    "        silence_durations = np.diff(intervals.ravel())[1::2] / sr\n",
    "        return np.any(silence_durations >= min_silence_duration)\n",
    "    return False\n",
    "\n",
    "def check_spectral_spread(audio, sr, threshold=0.8):\n",
    "    \"\"\"Check if the spectral spread exceeds the specified threshold.\"\"\"\n",
    "    spec = np.abs(librosa.stft(audio))\n",
    "    spectral_spread = np.sum(spec > np.mean(spec)) / spec.size\n",
    "    return spectral_spread > threshold\n",
    "\n",
    "def clean_audio(audio, sr, file_path, shared_discarded_files):\n",
    "    \"\"\"Cleans an audio file by removing noise, silence, and checking for spectral spread.\"\"\"\n",
    "    # Get file name for logging\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Check noise level\n",
    "    if is_too_noisy(audio, sr):\n",
    "        shared_discarded_files.append({'file_path': file_path, 'reason': 'too_noisy', 'snr': calculate_snr(audio)})\n",
    "        return None\n",
    "    \n",
    "    # Check for long silences\n",
    "    if has_long_silence(audio, sr):\n",
    "        audio = librosa.effects.trim(audio, top_db=20)[0]\n",
    "    \n",
    "    # Check spectral spread\n",
    "    if check_spectral_spread(audio, sr):\n",
    "        shared_discarded_files.append({'file_path': file_path, 'reason': 'bad_spectral_spread'})\n",
    "        return None\n",
    "    \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates or near-duplicates\n",
    "\n",
    "def get_audio_fingerprint(audio, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    return np.mean(mfccs, axis=1)\n",
    "\n",
    "def are_near_duplicates(audio1, sr1, audio2, sr2, threshold=0.95):\n",
    "    if len(audio1) == 0 or len(audio2) == 0:\n",
    "        raise ValueError(\"One or both audio files are empty\")\n",
    "    \n",
    "    if sr1 != sr2:\n",
    "        print(f\"Warning: Sample rates differ ({sr1} vs {sr2}). Resampling may be necessary.\")\n",
    "    \n",
    "    fp1 = get_audio_fingerprint(audio1, sr1)\n",
    "    fp2 = get_audio_fingerprint(audio2, sr2)\n",
    "    \n",
    "    if len(fp1) != len(fp2):\n",
    "        raise ValueError(\"Fingerprints have different lengths\")\n",
    "    \n",
    "    similarity = 1 - cosine(fp1, fp2)\n",
    "    return similarity > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(file_path, shared_duplicates, shared_discarded_files, target_length=5, overlap=0.5, target_sr=44100):\n",
    "    try:\n",
    "        # Load and clean the audio\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        audio = clean_audio(audio, sr, file_path, shared_discarded_files)\n",
    "        if audio is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Check for duplicates before processing\n",
    "        for existing_audio, existing_sr, existing_path in shared_duplicates:\n",
    "            if are_near_duplicates(audio, sr, existing_audio, existing_sr):\n",
    "                shared_discarded_files.append((file_path, 'duplicate'))\n",
    "                return None, None\n",
    "\n",
    "        # Resample if necessary\n",
    "        if sr != target_sr:\n",
    "            audio = librosa.resample(audio, sr, target_sr)\n",
    "            sr = target_sr\n",
    "            \n",
    "        # Convert target_length to samples\n",
    "        target_samples = sr * target_length\n",
    "        \n",
    "        # If audio is shorter than target length, pad with zeros\n",
    "        if len(audio) < target_samples:\n",
    "            audio = librosa.util.fix_length(audio, target_samples)\n",
    "        \n",
    "        # If audio is longer than target length, segment with overlap\n",
    "        else:\n",
    "            segments = []\n",
    "            for start in range(0, len(audio), int(target_samples * (1 - overlap))):\n",
    "                segment = audio[start:start + target_samples]\n",
    "                if len(segment) == target_samples:\n",
    "                    segments.append(segment)\n",
    "                elif len(segment) > 0:  # Handle the last segment if it's shorter\n",
    "                    segment = librosa.util.fix_length(segment, target_samples)\n",
    "                    segments.append(segment)\n",
    "            audio = np.array(segments)\n",
    "        \n",
    "        # Store the fingerprint of the processed audio to check against future files\n",
    "        shared_duplicates.append((audio, sr, file_path))\n",
    "\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {file_path}: {str(e)}\")\n",
    "        shared_discarded_files.append((file_path, f'error: {str(e)}'))\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(args):\n",
    "    row, audio_dir, output_dir, shared_duplicates, shared_discarded_files = args\n",
    "    file_path = os.path.join(audio_dir, row['file_name'])\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.warning(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    processed_audio, sr = process_audio(file_path, shared_duplicates, shared_discarded_files)\n",
    "    if processed_audio is None:\n",
    "        return None\n",
    "    \n",
    "    processed_data = []\n",
    "    if processed_audio.ndim == 2:\n",
    "        for i, segment in enumerate(processed_audio):\n",
    "            new_row = row.copy()\n",
    "            base_filename = f\"{os.path.splitext(row['file_name'])[0]}_segment_{i}\"\n",
    "            new_row['processed_file'] = f\"{base_filename}.wav\"\n",
    "            wavfile.write(os.path.join(output_dir, new_row['processed_file']), sr, segment)\n",
    "            processed_data.append(new_row)\n",
    "    else:\n",
    "        base_filename = f\"{os.path.splitext(row['file_name'])[0]}_processed\"\n",
    "        row['processed_file'] = f\"{base_filename}.wav\"\n",
    "        wavfile.write(os.path.join(output_dir, row['processed_file']), sr, processed_audio)\n",
    "        processed_data.append(row)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(converted_data, audio_dir, output_dir, n_processes=4):\n",
    "    manager = multiprocessing.Manager()\n",
    "    shared_duplicates = manager.list()\n",
    "    shared_discarded_files = manager.list()\n",
    "\n",
    "    with Pool(n_processes) as p:\n",
    "        results = list(tqdm(p.imap(\n",
    "            process_file, \n",
    "            [(row, audio_dir, output_dir, shared_duplicates, shared_discarded_files) \n",
    "             for _, row in converted_data.iterrows()]), \n",
    "            total=len(converted_data)))\n",
    "    \n",
    "    processed_data = [item for sublist in results if sublist is not None for item in sublist]\n",
    "\n",
    "    # Save discarded files to a DataFrame and export as CSV\n",
    "    discard_log_df = pd.DataFrame(list(shared_discarded_files), columns=['file_path', 'reason'])\n",
    "    discard_log_df.to_csv('discarded_audio_log.csv', index=False)\n",
    "\n",
    "    return pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "processed_dir = 'Processed Recordings'\n",
    "processed_data = process_dataset(converted_data, converted_dir, processed_dir)\n",
    "print('Audio Processing Complete')\n",
    "\n",
    "# Print completion message and count files in Processed Recordings directory\n",
    "processed_file_count = len([f for f in os.listdir(processed_dir) if f.endswith('.wav')])\n",
    "print(f\"\\nAudio processing is complete. There are now {processed_file_count} files in the '{processed_dir}' directory.\")\n",
    "\n",
    "# Output discarded files\n",
    "discard_log_df = pd.read_csv('discarded_audio_log.csv')\n",
    "if not discard_log_df.empty:\n",
    "    print(\"\\nThe following files were discarded:\")\n",
    "    for _, row in discard_log_df.iterrows():\n",
    "        print(f\"{row['file_path']}: {row['reason']}\")\n",
    "else:\n",
    "    print(\"\\nNo files were discarded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_data.info())\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "### Augment the processed audio files.\n",
    "- Pitch Shift\n",
    "- Time Stretch\n",
    "- add_noise\n",
    "- change_speed\n",
    "- apply_filter\n",
    "- add_background\n",
    "- time_shift\n",
    "- augment_audio\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_wind_sound(duration, sr):\n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    wind = np.random.normal(0, 0.1, int(sr * duration))\n",
    "    wind_filtered = np.convolve(wind, np.ones(1000)/1000, mode='same')\n",
    "    return wind_filtered / np.max(np.abs(wind_filtered))\n",
    "\n",
    "def generate_leaf_rustle(duration, sr):\n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    leaf = np.random.normal(0, 0.1, int(sr * duration))\n",
    "    envelope = np.exp(-t * 10) * np.sin(2 * np.pi * 2 * t)**2\n",
    "    return leaf * envelope / np.max(np.abs(leaf * envelope))\n",
    "\n",
    "def generate_water_sound(duration, sr):\n",
    "    t = np.linspace(0, duration, int(sr * duration), False)\n",
    "    water = np.random.normal(0, 0.1, int(sr * duration))\n",
    "    water_filtered = np.convolve(water, np.ones(500)/500, mode='same')\n",
    "    ripple = np.sin(2 * np.pi * 2 * t) * np.exp(-t * 2)\n",
    "    return (water_filtered + ripple) / np.max(np.abs(water_filtered + ripple))\n",
    "\n",
    "def mix_nature_sounds(duration, sr):\n",
    "    wind = generate_wind_sound(duration, sr)\n",
    "    leaf = generate_leaf_rustle(duration, sr)\n",
    "    water = generate_water_sound(duration, sr)\n",
    "    \n",
    "    mix = wind * 0.7 + leaf * 0.2 + water * 0.1\n",
    "    return mix / np.max(np.abs(mix))\n",
    "\n",
    "# Generate a 5-second mix of nature-like sounds\n",
    "sr = 44100\n",
    "duration = 5\n",
    "nature_background = mix_nature_sounds(duration, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pitch_shift(audio, sr, n_steps):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def time_stretch(audio, rate):\n",
    "    return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "def add_noise(audio, noise_factor):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    augmented_audio = audio + noise_factor * noise\n",
    "    return np.clip(augmented_audio, -1, 1)\n",
    "\n",
    "def change_speed(audio, speed_factor):\n",
    "    return librosa.effects.time_stretch(audio, rate=1/speed_factor)\n",
    "\n",
    "def apply_filter(audio, sr, filter_type='lowpass', cutoff=1000):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(4, normal_cutoff, btype=filter_type, analog=False)\n",
    "    return lfilter(b, a, audio)\n",
    "\n",
    "def add_background(audio, background, ratio=0.1):\n",
    "    if len(background) > len(audio):\n",
    "        start = np.random.randint(0, len(background) - len(audio))\n",
    "        background = background[start:start+len(audio)]\n",
    "    else:\n",
    "        background = np.pad(background, (0, max(0, len(audio) - len(background))))\n",
    "    return audio + ratio * background\n",
    "\n",
    "def time_shift(audio, shift_max, roll_prob=0.5):\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    if random.random() < roll_prob:\n",
    "        return np.roll(audio, shift)\n",
    "    else:\n",
    "        if shift > 0:\n",
    "            return np.pad(audio, (shift, 0))[:len(audio)]\n",
    "        else:\n",
    "            return np.pad(audio, (0, -shift))[:-shift]\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    augmentations = [\n",
    "        (pitch_shift, {'n_steps': random.uniform(-2, 2)}),\n",
    "        (time_stretch, {'rate': random.uniform(0.8, 1.2)}),\n",
    "        (add_noise, {'noise_factor': random.uniform(0.001, 0.015)}),\n",
    "        (change_speed, {'speed_factor': random.uniform(0.9, 1.1)}),\n",
    "        (apply_filter, {'filter_type': random.choice(['lowpass', 'highpass']),\n",
    "                        'cutoff': random.uniform(1000, 4000)}),\n",
    "        (time_shift, {'shift_max': int(sr * 0.5)})\n",
    "    ]\n",
    "    \n",
    "    # Randomly select 2-4 augmentations\n",
    "    num_augments = random.randint(2, 4)\n",
    "    selected_augments = random.sample(augmentations, num_augments)\n",
    "    \n",
    "    applied_augmentations = []\n",
    "    \n",
    "    # Apply selected augmentations\n",
    "    for augment_func, params in selected_augments:\n",
    "        audio = augment_func(audio, sr, **params)\n",
    "        applied_augmentations.append(f\"{augment_func.__name__}:{','.join(f'{k}={v}' for k, v in params.items())}\")\n",
    "    \n",
    "    # Add synthesized nature background\n",
    "    if random.random() < 0.5:\n",
    "        nature_background = mix_nature_sounds(len(audio) / sr, sr)\n",
    "        ratio = random.uniform(0.1, 0.3)\n",
    "        audio = add_background(audio, nature_background, ratio=ratio)\n",
    "        applied_augmentations.append(f\"add_background:ratio={ratio:.2f}\")\n",
    "    \n",
    "    return audio, applied_augmentations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_and_save(input_file, output_dir, num_augmentations=3):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(input_file, sr=None)\n",
    "        \n",
    "        augmented_files = []\n",
    "        all_applied_augmentations = []\n",
    "        \n",
    "        for i in range(num_augmentations):\n",
    "            # Apply augmentation\n",
    "            augmented_audio, applied_augmentations = augment_audio(audio, sr)\n",
    "            \n",
    "            # Generate new filename\n",
    "            base_name = os.path.basename(input_file)\n",
    "            name, ext = os.path.splitext(base_name)\n",
    "            new_name = f\"{name}_aug_{i+1}{ext}\"\n",
    "            output_path = os.path.join(output_dir, new_name)\n",
    "            \n",
    "            # Save augmented audio\n",
    "            sf.write(output_path, augmented_audio, sr)\n",
    "            \n",
    "            augmented_files.append(output_path)\n",
    "            all_applied_augmentations.append(';'.join(applied_augmentations))\n",
    "        \n",
    "        return augmented_files, all_applied_augmentations\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_file}: {str(e)}\")\n",
    "        return [], []\n",
    "\n",
    "\n",
    "def process_dataframe(df, input_dir, output_dir, num_augmentations=3):\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing files\"):\n",
    "        input_file = os.path.join(input_dir, row['file_path'])\n",
    "        augmented_files, augmentations = augment_and_save(input_file, output_dir, num_augmentations)\n",
    "        \n",
    "        for aug_file, aug_details in zip(augmented_files, augmentations):\n",
    "            new_row = row.copy()\n",
    "            new_row['file_path'] = os.path.relpath(aug_file, output_dir)\n",
    "            new_row['augmentations'] = aug_details\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    augmented_df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    return augmented_df\n",
    "\n",
    "# Usage\n",
    "input_dir = 'Processed Recordings'\n",
    "output_dir = 'Augmented Recordings'\n",
    "num_augmentations = 3\n",
    "\n",
    "\n",
    "# Process the dataframe\n",
    "augmented_data = process_dataframe(processed_data, input_dir, output_dir, num_augmentations)\n",
    "\n",
    "print(f\"Augmentation complete. {len(augmented_data) - len(processed_data)} new samples created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from the processed and augmented audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original recordings from dataset for feature extraction\n",
    "def filter_dataset(df, keep_dirs=['Processed Recordings', 'Augmented Recordings']):\n",
    "    # Convert keep_dirs to a set for faster lookup\n",
    "    keep_dirs_set = set(keep_dirs)\n",
    "    \n",
    "    # Function to check if a file path is in one of the keep_dirs\n",
    "    def is_keep_dir(file_path):\n",
    "        return any(dir_name in file_path for dir_name in keep_dirs_set)\n",
    "    \n",
    "    # Filter the dataframe\n",
    "    filtered_df = df[df['file_path'].apply(lambda x: is_keep_dir(x))]\n",
    "    \n",
    "    # Reset the index of the filtered dataframe\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    \n",
    "    # Print some information about the filtering process\n",
    "    print(f\"Original dataset size: {len(df)}\")\n",
    "    print(f\"Filtered dataset size: {len(filtered_df)}\")\n",
    "    print(f\"Removed {len(df) - len(filtered_df)} entries\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Usage\n",
    "filtered_data = filter_dataset(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(audio, sr):\n",
    "    # Mel-spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    \n",
    "    # Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    \n",
    "    # Spectral Rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    \n",
    "    return {\n",
    "        'mel_spectrogram_db': mel_spec_db,\n",
    "        'mfccs': mfccs,\n",
    "        'spectral_centroids': spectral_centroids,\n",
    "        'chroma': chroma,\n",
    "        'zero_crossing_rate': zero_crossing_rate,\n",
    "        'spectral_rolloff': spectral_rolloff\n",
    "    }\n",
    "\n",
    "def summarize_feature(feature):\n",
    "    if feature.ndim == 1:\n",
    "        return [np.mean(feature), np.std(feature), np.max(feature)]\n",
    "    elif feature.ndim == 2:\n",
    "        return np.hstack([\n",
    "            np.mean(feature, axis=1),\n",
    "            np.std(feature, axis=1),\n",
    "            np.max(feature, axis=1)\n",
    "        ])\n",
    "    \n",
    "def save_mel_spectrogram(mel_spec, output_dir, base_filename, sr):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spec, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{base_filename}_mel_spectrogram.png\"))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(file_path, output_dir):\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=sr)\n",
    "        features = extract_features(audio, sr)\n",
    "        \n",
    "        # Summarize features\n",
    "        feature_summary = {}\n",
    "        for key, value in features.items():\n",
    "            if key != 'mel_spectrogram':\n",
    "                feature_summary[f\"{key}_summary\"] = summarize_feature(value)\n",
    "        \n",
    "        # Create feature vector\n",
    "        feature_vector = np.hstack([\n",
    "            feature_summary.get('mfccs_summary', np.array([])),\n",
    "            feature_summary.get('spectral_centroids_summary', np.array([])),\n",
    "            feature_summary.get('chroma_summary', np.array([])),\n",
    "            feature_summary.get('zero_crossing_rate_summary', np.array([])),\n",
    "            feature_summary.get('spectral_rolloff_summary', np.array([]))\n",
    "            ])\n",
    "        \n",
    "        # Save mel-spectrogram as image\n",
    "        base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        save_mel_spectrogram(features['mel_spectrogram'], output_dir, base_filename)\n",
    "        \n",
    "        return feature_vector, features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Main processing loop\n",
    "def process_audio_files(filtered_data, output_dir):\n",
    "    feature_data = []\n",
    "    \n",
    "    for _, row in tqdm(filtered_data.iterrows(), total=len(filtered_data)):\n",
    "        file_path = row['file_name']\n",
    "        feature_vector, full_features = process_audio_file(file_path, output_dir)\n",
    "        \n",
    "        if feature_vector is not None and full_features is not None:\n",
    "            feature_dict = {\n",
    "                'file_name': file_path,\n",
    "                'feature_vector': feature_vector,\n",
    "            }\n",
    "            \n",
    "            # Add full feature arrays\n",
    "            for key, value in full_features.items():\n",
    "                feature_dict[f\"{key}_full\"] = value\n",
    "            \n",
    "            feature_data.append(feature_dict)\n",
    "    \n",
    "    return feature_data\n",
    "\n",
    "# Main execution\n",
    "output_dir = 'mel-spectrograms'\n",
    "final_data = process_audio_files(filtered_data, output_dir)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame([{'file_name': item['file_name'], 'feature_vector': item['feature_vector']} for item in final_data])\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('final_data.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Summary data saved to 'final_data.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
