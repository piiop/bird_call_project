{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load your data\n",
    "# Assuming X and y are already defined\n",
    "# X, y = load_your_data()  # replace with actual data loading\n",
    "\n",
    "# Initialize MLflow experiment\n",
    "mlflow.set_experiment(\"Bird Call Identification\")\n",
    "\n",
    "# Function to split data\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Define models to train\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Function to perform cross-validation, train, and log models with MLflow\n",
    "def train_and_log_models(models, X_train, y_train, X_test, y_test):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            # Create a pipeline with scaling and the model\n",
    "            pipeline = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
    "            \n",
    "            # Cross-validation\n",
    "            cv_scores = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='f1_macro')\n",
    "            avg_cv_score = np.mean(cv_scores)\n",
    "            print(f\"{model_name} CV F1 Score: {avg_cv_score}\")\n",
    "            \n",
    "            # Train on the entire training data\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            # Log metrics to MLflow\n",
    "            mlflow.log_param(\"Model\", model_name)\n",
    "            mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"F1 Macro\", f1_macro)\n",
    "            mlflow.log_metric(\"CV F1 Macro\", avg_cv_score)\n",
    "            \n",
    "            # Generate confusion matrix\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "            ax.set_title(f\"{model_name} Confusion Matrix\")\n",
    "            ax.set_xlabel(\"Predicted\")\n",
    "            ax.set_ylabel(\"Actual\")\n",
    "            \n",
    "            # Save the plot as an artifact\n",
    "            plt.savefig(f\"{model_name}_confusion_matrix.png\")\n",
    "            mlflow.log_artifact(f\"{model_name}_confusion_matrix.png\")\n",
    "            \n",
    "            # Close the plot to avoid overlap in the next iteration\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Print classification report\n",
    "            print(f\"Classification Report for {model_name}:\\n\", classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Log the model\n",
    "            mlflow.sklearn.log_model(pipeline, model_name)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "# Train and log models\n",
    "train_and_log_models(models, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, BatchNormalization, GRU\n",
    "from tensorflow.keras.layers import Input, Reshape\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already split and spectrograms are ready\n",
    "# X_train, X_test - shape (num_samples, height, width, channels)\n",
    "# y_train, y_test - shape (num_samples,)\n",
    "\n",
    "# Encode labels for neural network compatibility\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_train_categorical = to_categorical(y_train_encoded)\n",
    "y_test_categorical = to_categorical(y_test_encoded)\n",
    "\n",
    "# CNN model for spectrograms\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# LSTM model for spectrogram sequences\n",
    "def create_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Reshape(target_shape=(-1, input_shape[1] * input_shape[2]), input_shape=input_shape),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Function to train and log neural network models with MLflow\n",
    "def train_and_log_nn_models(X_train, y_train, X_test, y_test):\n",
    "    input_shape = X_train.shape[1:]  # (height, width, channels)\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    models = {\n",
    "        \"CNN\": create_cnn_model(input_shape, num_classes),\n",
    "        \"LSTM\": create_lstm_model(input_shape, num_classes)\n",
    "    }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            # Compile model\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            # Add EarlyStopping to prevent overfitting\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            \n",
    "            # Train model\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=30,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=2\n",
    "            )\n",
    "            \n",
    "            # Evaluate model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"{model_name} Test Accuracy: {accuracy}\")\n",
    "            \n",
    "            # Log parameters and metrics\n",
    "            mlflow.log_param(\"Model Type\", model_name)\n",
    "            mlflow.log_metric(\"Test Accuracy\", accuracy)\n",
    "            \n",
    "            # Save model to MLflow\n",
    "            mlflow.keras.log_model(model, model_name)\n",
    "            \n",
    "            # Plot training history\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "            \n",
    "            # Accuracy plot\n",
    "            ax[0].plot(history.history['accuracy'], label='train accuracy')\n",
    "            ax[0].plot(history.history['val_accuracy'], label='val accuracy')\n",
    "            ax[0].set_title(f\"{model_name} - Accuracy\")\n",
    "            ax[0].set_xlabel(\"Epochs\")\n",
    "            ax[0].set_ylabel(\"Accuracy\")\n",
    "            ax[0].legend()\n",
    "            \n",
    "            # Loss plot\n",
    "            ax[1].plot(history.history['loss'], label='train loss')\n",
    "            ax[1].plot(history.history['val_loss'], label='val loss')\n",
    "            ax[1].set_title(f\"{model_name} - Loss\")\n",
    "            ax[1].set_xlabel(\"Epochs\")\n",
    "            ax[1].set_ylabel(\"Loss\")\n",
    "            ax[1].legend()\n",
    "            \n",
    "            # Save plots as artifacts\n",
    "            plt.savefig(f\"{model_name}_training_history.png\")\n",
    "            mlflow.log_artifact(f\"{model_name}_training_history.png\")\n",
    "            \n",
    "            # Close plots\n",
    "            plt.close(fig)\n",
    "\n",
    "# Call the function with your spectrogram data\n",
    "train_and_log_nn_models(X_train, y_train_categorical, X_test, y_test_categorical)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
